---
title: "hw_3_jw4007"
output: github_document
---
```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# problem 1

### How many aisles are there, and which aisles are the most items ordered from?
```{r}
data("instacart")
instacart %>%
  group_by(aisle) %>%
  count(sort = TRUE)
```
There are 134 aisles and the aisles with the most items ordered is fresh vegetables.

### Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.
```{r}
aisle_1000 =
  count(instacart, aisle) %>%
  filter(n > 10000) %>%
  mutate(aisle = forcats::fct_reorder(aisle, n))

ggplot(aisle_1000, aes(x = aisle, y = n)) +
  geom_col() +
  labs(title = "The number of items ordered in each aisle",
       x = "aisle",
       y = "the number of items ordered") +
  theme(
    plot.title = element_text(size = 16),
    axis.title.x = element_text(size = 10),
    axis.title.y = element_text(size = 10),
    axis.text.y = element_text(size = 8)
  ) +
  coord_flip()
  
```

# problem 2

### Load, tidy, and create "weekday vs weekend" variable. 
```{r}
cardio = read.csv("./accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minutes",
    values_to = "activity_counts",
    names_prefix = "activity_"
  ) %>%
  mutate(weekday_vs_weekend = 
           ifelse(day == "Saturday", "weekend",
                  ifelse(day == "Sunday", "weekend", "weekday"))) %>%
  mutate(minutes = as.numeric(minutes)) %>%
  mutate(day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")))
```
There is `r nrow(cardio)` observations and `r ncol(cardio)` variables in the dataset. The variables are `r names(cardio)`

### Aggregate across minutes to create a total activity variable for each day, and create a table showing these totals. Are any trends apparent?
```{r}
daily_cardio = cardio %>%
  group_by(week, day) %>%
  summarise(daily_activity = sum(activity_counts)) %>%
  pivot_wider(names_from = day, values_from = daily_activity) 

knitr::kable(daily_cardio)
```
It seems that the daily activity on weekdays are less than weekends but the trend is not obvious.

### Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week.
```{r}
cardio %>%
  mutate(hour = rep(rep(seq(1, 24), each = 60), 35)) %>%
  mutate(hour = as.numeric(hour)) %>%
  group_by(week, day, hour) %>%
  summarize(hourly_activity = sum(activity_counts)) %>%
  ggplot(aes(x = hour, y = hourly_activity, color = day)) +
  geom_point() + geom_smooth(se = FALSE)
  labs(title = "24-hour avtivity time course",
       x = "Time(hour)",
       y = "Activity")
 
  
```
The graph shows that the user is more active after 10a.m. and becomes less active after 8 p.m.. Also, he is relatively more active at Friday and Saturday nights.

# Problem 3

### Load dataset
```{r}
library(p8105.datasets)
data("ny_noaa")
```
There is `r nrow(ny_noaa)` observations and `r ncol(ny_noaa)` variables in the dataset. The variables are `r names(ny_noaa)`, and they mean Weather station ID, Date of observation, Precipitation (tenths of mm), Snowfall (mm), Snow depth (mm), Maximum temperature (tenths of degrees C), Minimum temperature (tenths of degrees C) respectively.

### summarizing missing data. 
```{r}
noaa_missing = ny_noaa %>%
  summarize(across(prcp:tmin, ~sum(is.na(.)))) %>%
  pivot_longer(prcp:tmin, names_to = "variable_name", values_to = "percent_missing") %>%
  mutate(percent_missing = percent_missing/nrow(ny_noaa)*100)

knitr::kable(noaa_missing, digits = 1)
```
There is a problem of missing data in this dataset. The percentage of missing data in Precipitation, snowfall, and snow depth are 5.6, 14.7, and 22.8 relatively. More concernedly, almost half of the minimum and maximum temperature data are missing and this might cause an issue in analysis.

### Create separate variables for year, month, and day. Ensure observations for temperature, precipitation, and snowfall are given in reasonable units. 
```{r}
ny_noaa = ny_noaa %>%
  mutate(date = lubridate::ymd(date),
         year = lubridate::year(date),
         month = lubridate::month(date),
         month = as.factor(month),
         day = lubridate::day(date)) %>%
  mutate(tmax_c = as.numeric(tmax),
         tmin_c = as.numeric(tmin),
         prcp_mm = prcp,
         snow_mm = snow,
         snwd_mm = snwd)
```
### For snowfall, what are the most commonly observed values? Why?
```{r}
ny_noaa %>%
  group_by(snow_mm) %>%
  summarize(observed_snowfall = n()) %>%
  arrange(desc(observed_snowfall))
```
The most observed snowfall data is 0 because it doesn't snow most time of the year in New York.

### Make a two-panel plot showing the average max temperature in January and in July in each station across years.
```{r}
average_jan_p = 
  ny_noaa %>%
  filter(month == "1") %>%
  filter(!is.na(tmax_c)) %>%
  group_by(id, year) %>%
  summarize(average_tmax = mean(tmax_c)) %>%
  ggplot(aes(x = year, y = average_tmax, color = id)) +
  geom_path() + theme(legend.position = "none") +
  labs(title = "average max temperature in January",
       x = "year",
       y = "temperature (C)")

average_july_p = 
  ny_noaa %>%
  filter(month == "2") %>%
  filter(!is.na(tmax_c)) %>%
  group_by(id, year) %>%
  summarize(average_tmax = mean(tmax_c)) %>%
  ggplot(aes(x = year, y = average_tmax, color = id)) +
  geom_path() + theme(legend.position = "none") +
  labs(title = "average max temperature in July",
       x = "year",
       y = "temperature (C)")

(average_jan_p + average_july_p)
```
Overall, the tmax for for both months fluctuates across the years and it is obvious that the average tmax in July is generally higher than the average tmax in January. However, the temperature data collected by a few observatories produced outliers in the graph.

### (i) make a plot showing tmax vs tmin for the full dataset (note that a scatterplot may not be the best option)
```{r}
plot_i = ny_noaa %>%
  filter(!is.na(tmax_c), !is.na(tmin_c)) %>%
  ggplot(aes(x = tmax_c, y = tmin_c)) +
  geom_hex() + 
  labs(title = "maximum vs minimum temperature",
       x = "tmax (C)", y = "tmin (C)")
```

### (ii) make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year.
```{r}
plot_ii = ny_noaa %>%
  filter(snow > 0, snow < 100) %>%
  mutate(year = factor(year)) %>%
  ggplot(aes(x = snow, y = year, fill = year )) +
  geom_density_ridges() + theme(legend.position = "none") +
    labs(title = "the distribution of snowfall values greater than 0 and less than 100 separately by year", 
         x = "snowfall (mm)",
         y = "year")

```

### combining the above into a two panel plot
```{r}
plot_i + plot_ii
```


